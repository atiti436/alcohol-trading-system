import { NextRequest, NextResponse } from 'next/server'
import { GoogleGenerativeAI } from '@google/generative-ai'

/**
 * ğŸ¤– Room-6: åœ–ç‰‡OCRè¾¨è­˜ API
 * æ ¸å¿ƒåŠŸèƒ½ï¼šå ±å–®è¾¨è­˜ + å•†å“æ¨™ç±¤è­˜åˆ¥ + åƒ¹æ ¼è¡¨è§£æ
 */

// Google Gemini APIè¨­å®š (æ”¯æ´Vision)
const GEMINI_API_KEY = process.env.GOOGLE_GEMINI_API_KEY || ''
const genAI = new GoogleGenerativeAI(GEMINI_API_KEY)

// LINE Bot APIè¨­å®š
const LINE_CHANNEL_ACCESS_TOKEN = process.env.LINE_CHANNEL_ACCESS_TOKEN || ''

// OCRè¾¨è­˜æ¨¡æ¿
const OCR_PROMPTS = {
  customs_declaration: `
è«‹åˆ†æé€™å¼µå ±å–®åœ–ç‰‡ï¼Œæå–ä»¥ä¸‹è³‡è¨Šï¼š
1. å•†å“åç¨±å’Œæ•¸é‡
2. ç”³å ±åƒ¹å€¼å’Œè²¨å¹£
3. ç¨…å‰‡è™Ÿåˆ— (HS Code)
4. åŸç”¢åœ°
5. é‡é‡è³‡è¨Š
6. å…¶ä»–é‡è¦è³‡è¨Š

è«‹ä»¥çµæ§‹åŒ–çš„JSONæ ¼å¼å›æ‡‰ï¼ŒåŒ…å«confidenceè©•åˆ†ã€‚
`,

  product_label: `
è«‹åˆ†æé€™å¼µå•†å“æ¨™ç±¤ï¼Œæå–ä»¥ä¸‹è³‡è¨Šï¼š
1. å•†å“åç¨± (ä¸­æ–‡/è‹±æ–‡/æ—¥æ–‡)
2. å“ç‰Œ
3. é…’ç²¾åº¦æ•¸
4. å®¹é‡
5. ç”Ÿç”¢å¹´ä»½
6. ç”¢åœ°
7. åƒ¹æ ¼ (å¦‚æœ‰)
8. æ¢ç¢¼ (å¦‚æœ‰)

è«‹ä»¥çµæ§‹åŒ–çš„JSONæ ¼å¼å›æ‡‰ã€‚
`,

  price_list: `
è«‹åˆ†æé€™å¼µåƒ¹æ ¼è¡¨ï¼Œæå–ä»¥ä¸‹è³‡è¨Šï¼š
1. å•†å“æ¸…å–®å’Œå°æ‡‰åƒ¹æ ¼
2. è²¨å¹£å–®ä½
3. æœ‰æ•ˆæœŸé™ (å¦‚æœ‰)
4. æŠ˜æ‰£è³‡è¨Š (å¦‚æœ‰)
5. å‚™è¨»äº‹é …

è«‹ä»¥çµæ§‹åŒ–çš„JSONæ ¼å¼å›æ‡‰ï¼Œæ–¹ä¾¿ç³»çµ±è™•ç†ã€‚
`,

  invoice: `
è«‹åˆ†æé€™å¼µç™¼ç¥¨ï¼Œæå–ä»¥ä¸‹è³‡è¨Šï¼š
1. ç™¼ç¥¨è™Ÿç¢¼å’Œæ—¥æœŸ
2. è³£æ–¹å’Œè²·æ–¹è³‡è¨Š
3. å•†å“æ˜ç´°å’Œåƒ¹æ ¼
4. ç¨…é¡å’Œç¸½é‡‘é¡
5. ä»˜æ¬¾æ¢ä»¶

è«‹ä»¥çµæ§‹åŒ–çš„JSONæ ¼å¼å›æ‡‰ã€‚
`,

  general: `
è«‹åˆ†æé€™å¼µåœ–ç‰‡ä¸­çš„æ–‡å­—å…§å®¹ï¼Œç‰¹åˆ¥é—œæ³¨ï¼š
1. é…’é¡ç›¸é—œè³‡è¨Š
2. æ•¸å­—å’Œåƒ¹æ ¼
3. æ—¥æœŸ
4. é‡è¦çš„å•†æ¥­è³‡è¨Š

è«‹æä¾›ä¸­æ–‡èªªæ˜å’Œå»ºè­°ã€‚
`
}

// è¾¨è­˜çµæœå¾Œè™•ç†
interface OCRResult {
  type: 'customs_declaration' | 'product_label' | 'price_list' | 'invoice' | 'general'
  confidence: number
  extractedData: any
  summary: string
  suggestions: string[]
}

// å¾LINEç²å–åœ–ç‰‡
async function getImageFromLine(messageId: string): Promise<Buffer> {
  try {
    const response = await fetch(`https://api-data.line.me/v2/bot/message/${messageId}/content`, {
      headers: {
        'Authorization': `Bearer ${LINE_CHANNEL_ACCESS_TOKEN}`
      }
    })

    if (!response.ok) {
      throw new Error(`Failed to fetch image: ${response.statusText}`)
    }

    const arrayBuffer = await response.arrayBuffer()
    return Buffer.from(arrayBuffer)
  } catch (error) {
    console.error('Error fetching image from LINE:', error)
    throw error
  }
}

// æª¢æ¸¬åœ–ç‰‡é¡å‹
function detectImageType(extractedText: string): 'customs_declaration' | 'product_label' | 'price_list' | 'invoice' | 'general' {
  const text = extractedText.toLowerCase()

  if (text.includes('å ±å–®') || text.includes('æµ·é—œ') || text.includes('customs') || text.includes('hs code')) {
    return 'customs_declaration'
  }

  if (text.includes('ç™¼ç¥¨') || text.includes('invoice') || text.includes('çµ±ä¸€ç·¨è™Ÿ') || text.includes('tax id')) {
    return 'invoice'
  }

  if (text.includes('åƒ¹æ ¼è¡¨') || text.includes('price list') || text.includes('å®šåƒ¹') || text.includes('å ±åƒ¹')) {
    return 'price_list'
  }

  if (text.includes('ml') || text.includes('åº¦') || text.includes('%') || text.includes('å¹´ä»½') || text.includes('ç”¢åœ°')) {
    return 'product_label'
  }

  return 'general'
}

// ä½¿ç”¨Gemini Visioné€²è¡ŒOCR
async function performOCR(imageBuffer: Buffer, imageType?: string): Promise<OCRResult> {
  try {
    if (!GEMINI_API_KEY) {
      throw new Error('Gemini API key not configured')
    }

    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-pro' })

    // æº–å‚™åœ–ç‰‡æ•¸æ“š
    const imagePart = {
      inlineData: {
        data: imageBuffer.toString('base64'),
        mimeType: 'image/jpeg' // å‡è¨­æ˜¯JPEGï¼Œå¯¦éš›æ‡‰è©²æª¢æ¸¬
      }
    }

    // å…ˆåšåŸºæœ¬OCRç²å–æ–‡å­—
    const basicPrompt = "è«‹æå–é€™å¼µåœ–ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å…§å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼ã€‚"
    const basicResult = await model.generateContent([basicPrompt, imagePart])
    const extractedText = basicResult.response.text()

    // æª¢æ¸¬åœ–ç‰‡é¡å‹
    const detectedType = imageType as keyof typeof OCR_PROMPTS || detectImageType(extractedText)
    const specificPrompt = OCR_PROMPTS[detectedType]

    // ä½¿ç”¨ç‰¹å®šprompté€²è¡Œçµæ§‹åŒ–åˆ†æ
    const structuredResult = await model.generateContent([
      `æå–çš„æ–‡å­—å…§å®¹ï¼š${extractedText}\n\n${specificPrompt}`,
      imagePart
    ])

    const analysisResult = structuredResult.response.text()

    // å˜—è©¦è§£æJSONå›æ‡‰
    let extractedData = {}
    let confidence = 0.8

    try {
      // å°‹æ‰¾JSONéƒ¨åˆ†
      const jsonMatch = analysisResult.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        extractedData = JSON.parse(jsonMatch[0])
        confidence = 0.9
      }
    } catch (jsonError) {
      // å¦‚æœç„¡æ³•è§£æJSONï¼Œä½¿ç”¨åŸå§‹æ–‡å­—
      extractedData = { rawText: extractedText, analysis: analysisResult }
      confidence = 0.7
    }

    // ç”Ÿæˆæ‘˜è¦å’Œå»ºè­°
    const summary = generateSummary(detectedType, extractedData, extractedText)
    const suggestions = generateSuggestions(detectedType, extractedData)

    return {
      type: detectedType,
      confidence,
      extractedData,
      summary,
      suggestions
    }

  } catch (error) {
    console.error('OCR processing error:', error)
    throw error
  }
}

// ç”Ÿæˆæ‘˜è¦
function generateSummary(type: string, data: any, rawText: string): string {
  const typeNames = {
    customs_declaration: 'å ±å–®',
    product_label: 'å•†å“æ¨™ç±¤',
    price_list: 'åƒ¹æ ¼è¡¨',
    invoice: 'ç™¼ç¥¨',
    general: 'ä¸€èˆ¬æ–‡ä»¶'
  }

  const typeName = typeNames[type as keyof typeof typeNames] || 'æ–‡ä»¶'

  return `ğŸ“· å·²è¾¨è­˜${typeName}å…§å®¹

ğŸ” æå–åˆ°çš„é—œéµè³‡è¨Šï¼š
${rawText.length > 200 ? rawText.substring(0, 200) + '...' : rawText}

ğŸ“Š è¾¨è­˜é¡å‹ï¼š${typeName}
âœ… è¾¨è­˜å¯ä¿¡åº¦ï¼š${Math.round((data.confidence || 0.8) * 100)}%`
}

// ç”Ÿæˆå»ºè­°
function generateSuggestions(type: string, data: any): string[] {
  const suggestions: { [key: string]: string[] } = {
    customs_declaration: [
      'å»ºè­°å»ºç«‹å•†å“æª”æ¡ˆä»¥ä¾¿å¾ŒçºŒè¿½è¹¤',
      'å¯ä»¥å°‡ç¨…å‰‡è™Ÿåˆ—åŠ å…¥å•†å“è³‡æ–™',
      'ç•™æ„ç”³å ±åƒ¹å€¼æ˜¯å¦åˆç†',
      'ç¢ºèªåŸç”¢åœ°æ¨™ç¤ºæ­£ç¢º'
    ],
    product_label: [
      'å¯ä»¥å»ºç«‹æ–°å•†å“æª”æ¡ˆ',
      'è¨­å®šåˆé©çš„å”®åƒ¹å’Œåº«å­˜',
      'æ³¨æ„ä¿å­˜æ¢ä»¶è¦æ±‚',
      'ç¢ºèªé€²å£ç›¸é—œè­‰ä»¶'
    ],
    price_list: [
      'å¯ä»¥æ‰¹é‡æ›´æ–°å•†å“åƒ¹æ ¼',
      'æ³¨æ„åƒ¹æ ¼æœ‰æ•ˆæœŸé™',
      'æ¯”è¼ƒèˆ‡ç›®å‰å”®åƒ¹å·®ç•°',
      'è©•ä¼°åˆ©æ½¤ç©ºé–“'
    ],
    invoice: [
      'å»ºè­°å»ºç«‹æ‡‰ä»˜å¸³æ¬¾è¨˜éŒ„',
      'ç¢ºèªå•†å“å·²å…¥åº«',
      'æª¢æŸ¥ç™¼ç¥¨è³‡è¨Šæ˜¯å¦æ­£ç¢º',
      'å®‰æ’ä»˜æ¬¾äº‹å®œ'
    ],
    general: [
      'å¯ä»¥è£œå……æ›´å¤šå•†å“è³‡è¨Š',
      'å»ºè­°äººå·¥ç¢ºèªé‡è¦æ•¸æ“š',
      'ä¿å­˜åŸå§‹æ–‡ä»¶å‚™æŸ¥'
    ]
  }

  return suggestions[type] || suggestions.general
}

// POST /api/linebot/ocr - åœ–ç‰‡OCRè¾¨è­˜
export async function POST(request: NextRequest) {
  try {
    const { messageId, imageType, userId } = await request.json()

    if (!messageId) {
      return NextResponse.json(
        { error: 'Message ID is required' },
        { status: 400 }
      )
    }

    if (!LINE_CHANNEL_ACCESS_TOKEN) {
      return NextResponse.json(
        { error: 'LINE Bot not configured' },
        { status: 500 }
      )
    }

    // å¾LINEç²å–åœ–ç‰‡
    console.log(`Processing OCR for message ${messageId} from user ${userId}`)
    const imageBuffer = await getImageFromLine(messageId)

    // åŸ·è¡ŒOCRåˆ†æ
    const result = await performOCR(imageBuffer, imageType)

    // è¨˜éŒ„è™•ç†çµæœ
    console.log(`OCR completed for ${messageId}:`, {
      type: result.type,
      confidence: result.confidence,
      dataSize: JSON.stringify(result.extractedData).length
    })

    return NextResponse.json({
      success: true,
      data: result,
      metadata: {
        messageId,
        userId,
        processedAt: new Date().toISOString(),
        imageSize: imageBuffer.length
      }
    })

  } catch (error) {
    console.error('OCR API error:', error)

    // æä¾›fallbackå›æ‡‰
    const fallbackResult: OCRResult = {
      type: 'general',
      confidence: 0,
      extractedData: {},
      summary: 'ğŸ“· åœ–ç‰‡è¾¨è­˜åŠŸèƒ½æš«æ™‚ä¸å¯ç”¨',
      suggestions: [
        'è«‹ç¨å¾Œé‡è©¦',
        'æˆ–è¯ç¹«å®¢æœå”åŠ©è™•ç†',
        'ç¢ºä¿åœ–ç‰‡æ¸…æ™°å¯è®€'
      ]
    }

    return NextResponse.json({
      success: false,
      data: fallbackResult,
      error: 'åœ–ç‰‡è™•ç†å¤±æ•—',
      metadata: {
        error: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date().toISOString()
      }
    })
  }
}

// GET /api/linebot/ocr - OCRæœå‹™è³‡è¨Š
export async function GET() {
  const isConfigured = !!(GEMINI_API_KEY && LINE_CHANNEL_ACCESS_TOKEN)

  return NextResponse.json({
    service: 'OCR Recognition API',
    version: '1.0.0',
    configured: isConfigured,
    supportedTypes: [
      'customs_declaration',
      'product_label',
      'price_list',
      'invoice',
      'general'
    ],
    features: [
      'automatic_type_detection',
      'structured_data_extraction',
      'multi_language_support',
      'confidence_scoring'
    ],
    model: 'gemini-2.5-pro',
    timestamp: new Date().toISOString()
  })
}